stage_args:  
  - stage_id: 0  
    stage_type: llm  
    runtime:  
      process: true  
      devices: "0"  
      max_batch_size: 1  
    engine_args:  
      model_stage: thinker  
      model_arch: Qwen2_5OmniForConditionalGeneration  
      worker_type: ar  
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler  
      gpu_memory_utilization: 0.8  
      enforce_eager: true  
      trust_remote_code: true  
      engine_output_type: latent  
      enable_prefix_caching: false  
    is_comprehension: true  
    final_output: true  
    final_output_type: text  
  
  - stage_id: 1  
    stage_type: llm  
    runtime:  
      process: true  
      devices: "1"  
      max_batch_size: 1  
    engine_args:  
      model_stage: talker  
      model_arch: Qwen2_5OmniForConditionalGeneration  # Parent architecture  
      worker_type: ar  
      scheduler_cls: vllm_omni.core.sched.omni_ar_scheduler.OmniARScheduler  
      gpu_memory_utilization: 0.8  
      enforce_eager: true  
      trust_remote_code: true  
      engine_output_type: latent  
      enable_prefix_caching: false  
    engine_input_source: [0]  
    custom_process_input_func: vllm_omni.model_executor.stage_input_processors.qwen2_5_omni.thinker2talker  
  
  - stage_id: 2  
    stage_type: llm  
    runtime:  
      process: true  
      devices: "0"  
      max_batch_size: 1  
    engine_args:  
      model_stage: code2wav  
      model_arch: Qwen2_5OmniForConditionalGeneration  
      worker_type: generation  
      scheduler_cls: vllm_omni.core.sched.omni_generation_scheduler.OmniGenerationScheduler  
      gpu_memory_utilization: 0.15  
      enforce_eager: true  
      trust_remote_code: true  
      engine_output_type: audio  
    engine_input_source: [1]  
    final_output: true  
    final_output_type: audio  
  
runtime:  
  enabled: true  
  defaults:  
    window_size: -1  
    max_inflight: 1  
  edges:  
    - from: 0  
      to: 1  
      window_size: -1  
    - from: 1  
      to: 2  
      window_size: -1
